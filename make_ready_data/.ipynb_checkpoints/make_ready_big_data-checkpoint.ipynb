{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерим новые таблицы\n",
    "Все очень просто. Есть тренировочные пациенты и тестируемые пациенты.\n",
    "Так вот увеличивать данные будем так же в разных группах независимо, чтоб обучаясь на одном пациенте, классфикаторы не выдавали верный ответ только потому, что встретили знакомого пациента.\n",
    "\n",
    "Подробнее. \n",
    "\n",
    "Остановимся на особенностях нотбука: \n",
    "1. Для работы нужны только директория 'meas' и файл 'info.csv'. Они лежат в папке 'data'. \n",
    "2. К сожалению названия методов мало что говорят.\n",
    "3. нотбук создан после того как определились, что нужны только признаки RR, TQ, QTc,JTc, Tp-Te\n",
    "\n",
    "<br>plot_labels = ['RR', 'TQ', 'QTc', 'JTc', 'TpeakTend'] ------> WRONG!\n",
    "<br>plot_labels = ['QTc', 'JTc', 'TpeakTend', 'TQ', 'RR'] ------> CORRECT!\n",
    "\n",
    "В конце вызываются подряд три метода:\n",
    "1.  read_data(); returns:\n",
    "    1. info  ------------------- просто DataFrame с 'info.scv'; \n",
    "    2. final_filelist ---------- перечень тех файлов которые есть у нас и описаны в 'info.scv'\n",
    "\n",
    "2.  look_through_info(info, final_filelist); returns:\n",
    "    1. data_sick, data_heal ---- данные, где каждая строка - паттерн (иначе сэмпл), колонки - 5 признаков+label \n",
    "    2. inds_sick, inds_heal ---- строк сколько больных/здоровых пациентов. 2 колонки, во второй - сколько сэпплов в файле пациента, в первой - cumsum второй колонки (нужно для того, чтобы затем найти в data_sick, откуда сэмплы начинаются для этого пацента и где заканчиваются, метод: get_data_by_indexes)\n",
    "\n",
    "3.  get_train_and_test_sets(data_sick, data_heal, inds_sick, inds_heal, per_edge)\n",
    "    1. tr_d, ts_d -------------- уже готовые данные\n",
    "    2. tr_l, ts_l -------------- ответы к ним\n",
    "    \n",
    "В итоге данные будут в одинаковом объеме, граница количества больных срезается по количеству здоровых, поскольку здоровых меньше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dirpath=\"./\"):\n",
    "    info = pd.read_csv(dirpath+'data/info.csv')\n",
    "\n",
    "    # astype(int) for getting rid of '123123.0' and strings for next step\n",
    "    file_numbers = info['Номер ЭКГ'].dropna().astype(int).astype(str)\n",
    "\n",
    "    info_filelist = 'results' + file_numbers + '.csv'\n",
    "\n",
    "    meas_filelist = os.listdir(dirpath+'data/meas')\n",
    "\n",
    "    # form intersection of our 2 sets\n",
    "    final_filelist = set(info_filelist).intersection(meas_filelist)\n",
    "    \n",
    "    return info, final_filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = [RR, TQ, QTc, JTc, TpeakTend]\n",
    "# l = [QTc, JTc, TpeakTend, TQ, RR]\n",
    "\n",
    "def get_label(info, filename):\n",
    "\n",
    "    #     find the row with our name of file\n",
    "    row = info.loc[info['Номер ЭКГ'].isin([filename[7:-4]])]\n",
    "    \n",
    "    #     extract the and label of our file\n",
    "    answer = row['сердечно-сосудистое заболевание (при наличии)'].all()\n",
    "    \n",
    "    return (1 if answer == 'да' else 0)\n",
    "\n",
    "def get_feat(arrs) :\n",
    "    shiftedRR = np.sqrt(arrs[0,:-1].copy())\n",
    "    #     arrs.shape[1]-1 ---> -1 cause of first RR\n",
    "    newarrs = np.empty((5+1, arrs.shape[1]-1), dtype=float)\n",
    "    \n",
    "    newarrs[0,:] = arrs[2,1:] / shiftedRR                   #QTc = QT / shiftedRR\n",
    "    newarrs[1,:] = arrs[1,1:] / shiftedRR                   #JTc = JT / shiftedRR         \n",
    "    newarrs[2,:] = arrs[3,1:]                               #TpeakTend = TT\n",
    "    newarrs[3,:] = arrs[0,1:] - arrs[2,1:]                  #TQ = RR – QT\n",
    "    newarrs[4,:] = arrs[0,1:]                               #RR\n",
    "\n",
    "    return newarrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_through_info(info, final_filelist, dirpath=\"./\"):\n",
    "    \n",
    "    def fill_data(data, inds, ii, arr):\n",
    "        data = np.concatenate((data, arr.T))\n",
    "        inds[ii,0] = inds[ii-1,0] + inds[ii-1,1] # if ii == 0 then take inds[-1,0] == 0\n",
    "        inds[ii,1] = arr.shape[1]\n",
    "        return data, ii+1\n",
    "\n",
    "    len_list = len(final_filelist) # number of all files\n",
    "    \n",
    "    #     data of patients with label\n",
    "    data_sick = np.empty((0, 5 + 1), dtype=float)\n",
    "    data_heal = np.empty((0, 5 + 1), dtype=float)\n",
    "    \n",
    "    #     cumsum in 0-column and number of patterns in 1-column\n",
    "    inds_sick = np.zeros((len_list, 2), dtype=int)\n",
    "    inds_heal = np.zeros((len_list, 2), dtype=int)\n",
    "    i_sick = 0\n",
    "    i_heal = 0\n",
    "            \n",
    "    for filename in final_filelist :\n",
    "        df = pd.read_csv(dirpath+'data/meas/' + filename, \n",
    "                         skiprows=list(range(10))+[11, 15, 16]+list(range(17,99)), \n",
    "                         index_col=None, header=None)\n",
    "        data = df._get_numeric_data()\n",
    "        if data.shape[1] <= 1: # because RR will shorted by one\n",
    "            continue\n",
    "        arr = get_feat(data.values)\n",
    "        ans = get_label(info, filename)\n",
    "        arr[5] = ans\n",
    "        if ans == 1:\n",
    "            data_sick, i_sick = fill_data(data_sick, inds_sick, i_sick, arr)\n",
    "        else:\n",
    "            data_heal, i_heal = fill_data(data_heal, inds_heal, i_heal, arr)\n",
    "    inds_sick = inds_sick[:i_sick]\n",
    "    inds_heal = inds_heal[:i_heal]\n",
    "    \n",
    "    return data_sick, data_heal, inds_sick, inds_heal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test_sets(DataSick, DataHeal, IndsSick, IndsHeal, \n",
    "                            per_edge=0.8, balanced_data=True, make_shuffle=True):\n",
    "        \n",
    "    data_sick = DataSick.copy()\n",
    "    data_heal = DataHeal.copy()\n",
    "    inds_sick = IndsSick.copy() \n",
    "    inds_heal = IndsHeal.copy()\n",
    "    \n",
    "    #     number_of_health -- number of health patterns\n",
    "    #     take exactly helth because its less than sick \n",
    "    \n",
    "    number_of_health = inds_heal[-1,0] + inds_heal[-1,1]        \n",
    "    if balanced_data:\n",
    "        number_of_sick = number_of_health\n",
    "    else:\n",
    "        number_of_sick = inds_sick[-1,0] + inds_sick[-1,1]\n",
    "        \n",
    "    edge1_heal = int(number_of_health * per_edge) # how much is train patterns for heal people\n",
    "    edge2_heal= number_of_health\n",
    "    edge1_sick = int(number_of_sick * per_edge) # how much is train patterns for sick people\n",
    "    edge2_sick= number_of_sick\n",
    "    \n",
    "    def get_data_by_indexes(ready_data, inds):\n",
    "        data = np.empty((0,5+1))\n",
    "        for i in range(inds.shape[0]):\n",
    "            start = inds[i,0]\n",
    "            end = start + inds[i,1]\n",
    "            data = np.concatenate((data, ready_data[start:end]))\n",
    "        return data\n",
    "        \n",
    "    def form_list_of_test_patients(ready_data, ind_test):\n",
    "        patient_data_list = []\n",
    "        for i in range(ind_test.shape[0]):\n",
    "            start = ind_test[i,0]\n",
    "            end = start + ind_test[i,1]\n",
    "            patient_data_list.append(ready_data[start:end])\n",
    "        return patient_data_list\n",
    "        \n",
    "    \n",
    "    def get_train_test_data(ready_data, inds, edge1, edge2):\n",
    "        if make_shuffle:\n",
    "            np.random.shuffle(inds)\n",
    "        ind_cumsum = np.cumsum(inds[:,1])\n",
    "        ind_train = inds[ind_cumsum <= edge1]\n",
    "        ind_test = inds[(ind_cumsum > edge1) * (ind_cumsum<=edge2)]\n",
    "        train_data = get_data_by_indexes(ready_data, ind_train)\n",
    "        test_data = get_data_by_indexes(ready_data, ind_test)\n",
    "        patient_data_list = form_list_of_test_patients(ready_data, ind_test)\n",
    "        return train_data, test_data, patient_data_list\n",
    "        \n",
    "    tr_s, ts_s, patient_data_s =  get_train_test_data(data_sick, inds_sick, edge1_sick, edge2_sick)\n",
    "    tr_h, ts_h, patient_data_h = get_train_test_data(data_heal, inds_heal, edge1_heal, edge2_heal)\n",
    "\n",
    "    patient_data = patient_data_h + patient_data_s    \n",
    "    \n",
    "    train = np.concatenate((tr_s,tr_h))\n",
    "    test = np.concatenate((ts_s,ts_h))\n",
    "\n",
    "    if make_shuffle:\n",
    "        np.random.shuffle(train)\n",
    "        np.random.shuffle(test)\n",
    "        \n",
    "    return train[:,:5], test[:,:5], train[:,5], test[:,5], patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info, final_filelist = read_data(dirpath=\"../\")\n",
    "# data_sick, data_heal, inds_sick, inds_heal = look_through_info(info, final_filelist, dirpath=\"../\")\n",
    "# tr_d, ts_d, tr_l, ts_l, patient_data = \\\n",
    "#                 get_train_and_test_sets(data_sick, data_heal, inds_sick, inds_heal, 1, balanced_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41 здоровых пациентов, 70 больных. Соответственно, всего 111 пациентов.\n",
    "У здоровых пациентов суммарно всего 994 сэмплов. У больных - 1549. Соответственно, всего 2543 сэмлпов для обучения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
